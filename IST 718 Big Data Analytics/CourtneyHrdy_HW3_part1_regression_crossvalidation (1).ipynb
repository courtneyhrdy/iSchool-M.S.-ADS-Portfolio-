{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7da89413c16b9232417a288f5f4a90d5",
     "grade": false,
     "grade_id": "cell-b11b633c1b5945fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Professor: Daniel Acuna <deacuna@syr.edu>\n",
    "\n",
    "## General instructions:\n",
    "\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers either from your classmates or from the internet__\n",
    "- You can put the homework files anywhere you want in your http://notebook.acuna.io workspace but _do not change_ the file names. The TAs and the professor use these names to grade your homework.\n",
    "- Remove or comment out code that contains `raise NotImplementedError`. This is mainly to make the `assert` statement fail if nothing is submitted.\n",
    "- The tests shown in some cells (i.e., `assert` and `np.testing.` statements) are used to grade your answers. **However, the professor and TAs will use __additional__ test for your answer. Think about cases where your code should run even if it passess all the tests you see.**\n",
    "- Before downloading and submitting your work through Blackboard, remember to save and press `Validate` (or go to \n",
    "`Kernel`$\\rightarrow$`Restart and Run All`). \n",
    "- Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3fe2047354b19195bdf5522cbf281619",
     "grade": false,
     "grade_id": "cell-018f7df76fbe7856",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the packages needed for this part\n",
    "# create spark and sparkcontext objects\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "import pyspark\n",
    "from pyspark.ml import feature, regression, Pipeline\n",
    "from pyspark.sql import functions as fn, Row\n",
    "from pyspark import sql\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8cf2044a50756dcbf5ea6c35bf7d42f1",
     "grade": false,
     "grade_id": "cell-baf717df615c90b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 1: Admission analysis\n",
    "\n",
    "In this assignment, you will have to do an analysis on graduate admission dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a10d9c9cd49d50cafb359604a884025d",
     "grade": false,
     "grade_id": "cell-b3d0fec5fd8fa1aa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Admission data analysis\n",
    "```console\n",
    "1. Title: Graduate Admission Data\n",
    "\n",
    "2. Sources:\n",
    "    Mohan S Acharya, Asfia Armaan, Aneeta S Antony : A Comparison of Regression Models for Prediction of Graduate Admissions, IEEE International Conference on Computational Intelligence in Data Science 2019\n",
    "    \n",
    "3. Number of Instances: 400\n",
    "\n",
    "4. Numer of Attributes: 8 + numeric chance of admit \n",
    "\n",
    "5. Attribute information:\n",
    "    \n",
    "    1. Region: A,B,C,D,E\n",
    "    2. GRE_Score: out of 340\n",
    "    3. TOEFL_Scores: out of 120 \n",
    "    4. University_Rating: out of 5 \n",
    "    5. SOP (Statement of Purpose): out of 5\n",
    "    6. LOR (Letter of Recommendation): out of 5 \n",
    "    7. CGPA (Undergraduate GPA): out of 10 \n",
    "    8. Research (Research Experience): either 0 or 1 \n",
    "    9. Chance_of_Admit: ranging from 0 to 1 \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba156df7460502db19587cedd3920ffd",
     "grade": false,
     "grade_id": "cell-fbd13f1a46d7ab58",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "admission_df = spark.createDataFrame(pd.read_csv('Admission_Predict.csv', sep=','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6101064f7058d337cfc70fd28780d64e",
     "grade": false,
     "grade_id": "cell-7a1ec8f49ea0c803",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 1. Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With big data, datasets can be too big to bring them into the Spark client. However, we can use the `limit` method of a dataframe to limit the number of rows to bring as a Pandas dataframe.\n",
    "\n",
    "Create a dataframe `admission_sample_df` with the first 30 rows of `admission_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e89e882063996b7dab8a5242e3929d2b",
     "grade": false,
     "grade_id": "cell-e80e04372b503a3e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create \n",
    "admission_sample_df = admission_df.limit(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "247f4c0aaa64fbba85f4f2e661b003d9",
     "grade": true,
     "grade_id": "cell-57638388c2ad5eb0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 1 pts - right number of rows\n",
    "np.testing.assert_equal(admission_sample_df.count(), 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c559cf4b7166497727bcb57c9b32e8bd",
     "grade": false,
     "grade_id": "cell-21369ae318d400ec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(7 pts)** Below, transform `admission_sample_df` into a Pandas dataframe and do a scatter plot of `GRE_Score` vs `TOEFL_Score`. In addition, grouping each point with different color based on `Chance_of_Admit`. If the chance over 0.6, colored the points blue; otherwise, colored the points red. Last, describe what you find? (Remember to add **axis titles**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aeacc9bfe1d258f16eaa1f74412e08f3",
     "grade": true,
     "grade_id": "cell-733193a16ed546b6",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts: Scatter plot of GRE_Score vs TOEFL_Score\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import numpy as np\n",
    "df = admission_sample_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    30.000000\n",
       "mean      0.698000\n",
       "std       0.158949\n",
       "min       0.440000\n",
       "25%       0.612500\n",
       "50%       0.670000\n",
       "75%       0.795000\n",
       "max       0.970000\n",
       "Name: Chance_of_Admit, dtype: float64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Chance_of_Admit.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     30.000000\n",
       "mean     318.866667\n",
       "std       11.515307\n",
       "min      295.000000\n",
       "25%      311.250000\n",
       "50%      320.000000\n",
       "75%      326.500000\n",
       "max      340.000000\n",
       "Name: GRE_Score, dtype: float64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.GRE_Score.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['color'] = np.where(df['Chance_of_Admit'] >= 0.6, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "admitg6 = df[df['color'] == 1]\n",
    "admitl6 = df[df['color'] == 0]\n",
    "ax0 = admitg6.plot(x='GRE_Score', y='TOEFL_Score', kind='scatter', color='blue')\n",
    "ax1 = admitl6.plot(x='GRE_Score', y='TOEFL_Score', kind='scatter', color='red', ax=ax0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5cebbce497e4fb9cd495a8efd39a760d",
     "grade": true,
     "grade_id": "cell-dd7a31bc0ef827f8",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 2 pts: What you find based on the scatter plot?\n",
    "# Some of the lowest TOEFL and GRE scores have the lowest chance of admission, but there are outliers \n",
    "# Applicants with GRE scores above 320 have the highest chance of admission, but with lower TOEFL scores chance of admission decreases \n",
    "# Applicants with TOEFL scores above 110 have the highest chance of admission\n",
    "# Half of applicants in the dataset have above a 67% chance of admission\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7ebd53bbced4b999f064706dad37dbdf",
     "grade": false,
     "grade_id": "cell-ec142e2e68de9605",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Perform correlations between SOP, LOR, and CGPA\n",
    "\n",
    "Create a `admission_corr_df` dataframe that contains the correlations between `SOP` and `LOR` as a column `corr_SOP_LOR`, between `LOR` and `CGPA` as `corr_LOR_CGPA`, and `SOP` and `CGPA` as `corr_SOP_CGPA`. (Using admission_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb56146a17e5c327622b6f1e1760d965",
     "grade": false,
     "grade_id": "cell-df532240f4d92753",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "admission_corr_df = admission_df.select(fn.corr('SOP', 'LOR').alias('corr_SOP_LOR'), fn.corr(\"LOR\", \"CGPA\").alias('corr_LOR_CGPA'), fn.corr(\"SOP\", \"CGPA\").alias('corr_SOP_CGPA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b6f6eea28b7090b37cbb3c9c66b9f3f1",
     "grade": true,
     "grade_id": "cell-cc77c0b74fa5348e",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 3 pts\n",
    "np.testing.assert_equal(set(admission_corr_df.columns), \n",
    "                        {'corr_SOP_LOR', 'corr_LOR_CGPA', 'corr_SOP_CGPA'})\n",
    "np.testing.assert_almost_equal(list(admission_corr_df.first().asDict().values()),\n",
    "                               [0.7295925366175836, 0.6702112958281646, 0.718143958057528], decimal=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c29c5107e1156893d1906558b8878af8",
     "grade": false,
     "grade_id": "cell-6a8aaa697c9bbf35",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Compute mean and standard deviation Change_of_Admit for regions\n",
    "\n",
    "Create `region_chance_df` with the column `region`, `avg_chance`, and `sd_chance`, where `avg_chance` is the average chance of admit in different regions and `sd_chance` is the standard deviation of chance of admit. Sort the resulting dataframe from highest to lowest average chance of admit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9bf6636af715d9bd16c4ac9b7e5f6b3c",
     "grade": false,
     "grade_id": "cell-adc9962ca3f172dd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "region_chance_df = admission_df.groupby('region').agg(fn.mean('Chance_of_Admit').alias('avg_chance'), fn.stddev('Chance_of_Admit').alias('sd_chance')) \n",
    "\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "42c6eedfeb2f9a67085849ddc44eada2",
     "grade": true,
     "grade_id": "cell-3e3efa19ef277303",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_array_almost_equal(\n",
    "    (region_chance_df.orderBy('region').select('avg_chance').\\\n",
    "     rdd.map(lambda x: list(x.asDict().values())).collect()),\n",
    "[[0.7283529411764705],\n",
    " [0.712],\n",
    " [0.7020000000000001],\n",
    " [0.734],\n",
    " [0.7501538461538463]], decimal=3)\n",
    "\n",
    "np.testing.assert_array_almost_equal(\n",
    "    (region_chance_df.orderBy('region').select('sd_chance').\\\n",
    "     rdd.map(lambda x: list(x.asDict().values())).collect()),\n",
    "[[0.1474533587179311],\n",
    " [0.13247461571759256],\n",
    " [0.14784014630931444],\n",
    " [0.14602022038712573],\n",
    " [0.1364103678667368]], decimal=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "33d5db8971f43434dd99419e3704dea3",
     "grade": false,
     "grade_id": "cell-f1bd9070a4f4a096",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ce1b2c674f73f01533a2d819960d904b",
     "grade": false,
     "grade_id": "cell-398550c98eadbc15",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Dummy variables for region\n",
    "Create a dataframe `dummy_df` with columns `region` as dummy variables, and columns `GRE_Score`, `TOEFL_Score`, `CGPA`, `University_Rating`, and `Chance_of_Admit`. Use region B as the baselines and name the dummy variables `region_A` for region `A` and so on. The dataframe `dummy_df` should not contain the column `region` but only its dummy variable representations. **All column types should be float or integer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "769b5022f018ff379dbc2f57c32cd0e7",
     "grade": false,
     "grade_id": "cell-db7e48e683df42e1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   GRE_Score          400 non-null    int64  \n",
      " 1   TOEFL_Score        400 non-null    int64  \n",
      " 2   CGPA               400 non-null    float64\n",
      " 3   University_Rating  400 non-null    int64  \n",
      " 4   Chance_of_Admit    400 non-null    float64\n",
      " 5   Region_A           400 non-null    int64  \n",
      " 6   Region_C           400 non-null    int64  \n",
      " 7   Region_D           400 non-null    int64  \n",
      " 8   Region_E           400 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 28.2 KB\n",
      "root\n",
      " |-- GRE_Score: long (nullable = true)\n",
      " |-- TOEFL_Score: long (nullable = true)\n",
      " |-- CGPA: double (nullable = true)\n",
      " |-- University_Rating: long (nullable = true)\n",
      " |-- Chance_of_Admit: double (nullable = true)\n",
      " |-- Region_A: long (nullable = true)\n",
      " |-- Region_C: long (nullable = true)\n",
      " |-- Region_D: long (nullable = true)\n",
      " |-- Region_E: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#admission_df.groupby('region').agg(fn.mean('GRE_Score')).show()\n",
    "\n",
    "df = admission_df.toPandas()\n",
    "df['Region_A'] = np.where(df['Region'] == 'A', 1, 0)\n",
    "df['Region_B'] = np.where(df['Region'] == 'B', 1, 0)\n",
    "df['Region_C'] = np.where(df['Region'] == 'C', 1, 0)\n",
    "df['Region_D'] = np.where(df['Region'] == 'D', 1, 0)\n",
    "df['Region_E'] = np.where(df['Region'] == 'E', 1, 0)\n",
    "\n",
    "df = df[['GRE_Score','TOEFL_Score', 'CGPA', 'University_Rating','Chance_of_Admit', 'Region_A', 'Region_C', 'Region_D', 'Region_E']]\n",
    "df.info()\n",
    "dummy_df = spark.createDataFrame(df)\n",
    "dummy_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08e681251ccb2ff430f5575dedc3b271",
     "grade": true,
     "grade_id": "cell-f39fae1fa71a3471",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_equal(len(dummy_df.columns), 9)\n",
    "np.testing.assert_equal(dummy_df.select(fn.sum('Region_A')).first()['sum(Region_A)'], 85)\n",
    "np.testing.assert_equal(dummy_df.select(fn.sum('Region_D')).first()['sum(Region_D)'], 85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "92b51a725e97536342f8267337dc1cf1",
     "grade": false,
     "grade_id": "cell-8cce282528966eda",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Model comparison\n",
    "\n",
    "In the next set of questions, you will use the splits below to fit, validate, and estimate the generalization error of your models. The `randomSplit` is called with a seed so that it does not change from what the professor used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "09f7584104f099b4df6ffa35060ccfe6",
     "grade": false,
     "grade_id": "cell-b08585ead9b207b9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# points in training:  227\n",
      "# points in validation:  126\n",
      "# points in testing:  47\n"
     ]
    }
   ],
   "source": [
    "training_df, validation_df, testing_df = dummy_df.randomSplit([0.6, 0.3, 0.1], seed=0)\n",
    "print(\"# points in training: \", training_df.count())\n",
    "print(\"# points in validation: \", validation_df.count())\n",
    "print(\"# points in testing: \", testing_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f8d66ab79dcdf24c5f81fee9f4b36e39",
     "grade": false,
     "grade_id": "cell-d0b5fb8d8706846a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Propose three regression models\n",
    "\n",
    "In the next section, you will choose the best model to explain the data in `admission_df`. Select the right split of the data for the right step of the process (i.e., training, validation, and testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3062054c474545b66a732399049ed7a6",
     "grade": false,
     "grade_id": "cell-dcd785c97986afcf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Model 1: Fit model with only `GRE_Score`\n",
    "\n",
    "Create a pipeline that takes **GRE_Score** as a feature to predict **Chance_of_Admit** and fits a linear regression model. You should start your pipeline by taking the appropriate column or columns from `dummy_df`. Assign the fit pipeline transformer to `pipe_model1`. Your pipeline must have one vector assembler followed by a linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/daniel-acuna/pyspark_pipes.git\n",
      "  Cloning https://github.com/daniel-acuna/pyspark_pipes.git to /private/var/folders/p4/l5_451cn5p9gmxv7541xf3n80000gn/T/pip-req-build-_duwwv50\n",
      "  Running command git clone -q https://github.com/daniel-acuna/pyspark_pipes.git /private/var/folders/p4/l5_451cn5p9gmxv7541xf3n80000gn/T/pip-req-build-_duwwv50\n",
      "Requirement already satisfied: pyspark in ./opt/anaconda3/lib/python3.8/site-packages (from pyspark-pipes==0.1) (3.1.1)\n",
      "Requirement already satisfied: py4j==0.10.9 in ./opt/anaconda3/lib/python3.8/site-packages (from pyspark->pyspark-pipes==0.1) (0.10.9)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Users/courtneyhrdy/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/daniel-acuna/pyspark_pipes.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38a5462f85e2da429c5aa44985fd390d",
     "grade": false,
     "grade_id": "cell-c57d53ae996b4bde",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import regression\n",
    "from pyspark.ml import feature\n",
    "\n",
    "pipe_model1 = Pipeline(stages=[\n",
    "  feature.VectorAssembler(inputCols=['GRE_Score'], outputCol='features'),\n",
    "  regression.LinearRegression(featuresCol='features', labelCol='Chance_of_Admit')  \n",
    "]).fit(training_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e25e1c67814e76189a4a6ae37ee6bf0",
     "grade": true,
     "grade_id": "cell-a4893e248e800735",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_equal(type(pipe_model1.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_model1.stages[1]), regression.LinearRegressionModel)\n",
    "np.testing.assert_array_equal(pipe_model1.stages[1].coefficients.shape, (1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7db4ca6b9b8ef5cffd712581320f6325",
     "grade": false,
     "grade_id": "cell-0a32f35acf305854",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Model 2: Fit model with `GRE_Score` and `TOEFL_Score`\n",
    "\n",
    "Follow the same idea as above and create a pipeline transformer `pipe_model2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c188642a605c3326448242ce9f8a2597",
     "grade": false,
     "grade_id": "cell-1d6b9d8550b155a0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "pipe_model2 = Pipeline(stages=[\n",
    "  feature.VectorAssembler(inputCols=['GRE_Score', 'TOEFL_Score'], outputCol='features'),\n",
    "  regression.LinearRegression(featuresCol='features', labelCol='Chance_of_Admit')  \n",
    "]).fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+----+-----------------+---------------+--------+--------+--------+--------+\n",
      "|GRE_Score|TOEFL_Score|CGPA|University_Rating|Chance_of_Admit|Region_A|Region_C|Region_D|Region_E|\n",
      "+---------+-----------+----+-----------------+---------------+--------+--------+--------+--------+\n",
      "|      298|         98| 7.5|                2|           0.44|       1|       0|       0|       0|\n",
      "|      299|        106| 8.4|                2|           0.64|       1|       0|       0|       0|\n",
      "|      300|         97| 8.1|                2|           0.65|       0|       1|       0|       0|\n",
      "|      302|        102| 8.0|                1|            0.5|       0|       0|       1|       0|\n",
      "|      303|        102| 8.5|                3|           0.62|       0|       0|       0|       0|\n",
      "|      304|        105| 7.5|                1|           0.52|       0|       0|       0|       0|\n",
      "|      307|        109| 8.0|                3|           0.62|       0|       0|       0|       0|\n",
      "|      308|        101| 7.9|                2|           0.68|       0|       0|       1|       0|\n",
      "|      310|         99| 7.3|                2|           0.54|       1|       0|       0|       0|\n",
      "|      311|        104| 8.2|                3|           0.61|       0|       0|       1|       0|\n",
      "|      312|        107| 7.9|                3|           0.64|       1|       0|       0|       0|\n",
      "|      313|        107| 8.5|                2|           0.53|       0|       0|       0|       0|\n",
      "|      314|        103|8.21|                2|           0.65|       0|       0|       0|       0|\n",
      "|      314|        105| 8.3|                3|           0.54|       1|       0|       0|       0|\n",
      "|      316|        105| 8.2|                2|           0.49|       1|       0|       0|       0|\n",
      "|      319|        106| 8.0|                3|           0.65|       1|       0|       0|       0|\n",
      "|      320|        110| 9.2|                5|           0.88|       0|       0|       0|       0|\n",
      "|      321|        109| 8.2|                3|           0.75|       0|       1|       0|       0|\n",
      "|      322|        109| 8.8|                5|           0.76|       0|       0|       0|       1|\n",
      "|      322|        110|8.67|                3|            0.8|       0|       0|       0|       1|\n",
      "+---------+-----------+----+-----------------+---------------+--------+--------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "782baea21ff61b85fa180ef34a127f9c",
     "grade": true,
     "grade_id": "cell-8101d487ebf43e04",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_equal(type(pipe_model2.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_model2.stages[1]), regression.LinearRegressionModel)\n",
    "np.testing.assert_array_equal(pipe_model2.stages[1].coefficients.shape, (2,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "235be53a2ceb6affa1113f0edbcc156f",
     "grade": false,
     "grade_id": "cell-3a4584e870d7917f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Model 3: Fit model with region, GRE_Score, TOEFL_Score, CGPA, and Univeristy_Rating\n",
    "\n",
    "Follow the same idea as above and create a pipeline transformer `pipe_model3`. Remember that some features have been feature engineered. In particular, use the transformed columns in the order: region, GRE_Score, TOEFL_Score, CGPA, and Univeristy_Rating. Choose the columns from `dummy_df` appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34ea814c7a5da239f558a32fb8e3391d",
     "grade": false,
     "grade_id": "cell-d76114eb3ef2a204",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "pipe_model3 = Pipeline(stages=[feature.VectorAssembler(inputCols = ['Region_A', 'Region_C', 'Region_D', 'Region_E','GRE_Score', 'TOEFL_Score', 'CGPA', 'University_Rating'], \n",
    "                                              outputCol='features'),\n",
    "                              regression.LinearRegression(featuresCol='features', labelCol='Chance_of_Admit')\n",
    "                              ]).fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegressionModel: uid=LinearRegression_326fe93953db, numFeatures=8"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_model3.stages[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5bd910c7fecdadc8ed7d3625be48d8e7",
     "grade": true,
     "grade_id": "cell-3fec64f09c5f9b1a",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_equal(type(pipe_model3.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_model3.stages[1]), regression.LinearRegressionModel)\n",
    "np.testing.assert_array_equal(pipe_model3.stages[1].coefficients.shape, (8,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "03cb166d70623c95bd8e3926dcc93069",
     "grade": false,
     "grade_id": "cell-8ae6c91ed48801ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Compare models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a3cfcdda4fbb7ff90ad0f41752c2c8d2",
     "grade": false,
     "grade_id": "cell-1c77f9181d77846f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Estimate RMSE on validation data for the three models\n",
    "\n",
    "Create three dataframes `rmse1_df`, `rmse2_df`, and `rmse3_df` for models 1, 2, and 3, respectively, with only column `rmse`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "44c43910e53176dc89129126996e1c29",
     "grade": false,
     "grade_id": "cell-4868fed0a63693a8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create rmse1_df, rmse2_df, and rmse3_df dataframes below\n",
    "from pyspark.sql import functions as fn\n",
    "from pyspark.sql.functions import *\n",
    "rmse = fn.sqrt(fn.mean((fn.col('Chance_of_Admit') - fn.col('prediction'))**2)).alias('rmse')\n",
    "\n",
    "\n",
    "rmse1_df = pipe_model1.transform(training_df).select(rmse)\n",
    "rmse2_df = pipe_model2.transform(training_df).select(rmse)\n",
    "rmse3_df = pipe_model3.transform(training_df).select(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|               rmse|\n",
      "+-------------------+\n",
      "|0.08161124716698956|\n",
      "+-------------------+\n",
      "\n",
      "+-------------------+\n",
      "|               rmse|\n",
      "+-------------------+\n",
      "|0.07451896176272202|\n",
      "+-------------------+\n",
      "\n",
      "+-------------------+\n",
      "|               rmse|\n",
      "+-------------------+\n",
      "|0.06296444607202685|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display the answers here\n",
    "rmse1_df.show()\n",
    "rmse2_df.show()\n",
    "rmse3_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8667bcddbc78ac0063269e8ec38f7bda",
     "grade": true,
     "grade_id": "cell-3b822c91b066bf09",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_equal(rmse1_df.count(), 1)\n",
    "np.testing.assert_equal(rmse2_df.count(), 1)\n",
    "np.testing.assert_equal(rmse3_df.count(), 1)\n",
    "np.testing.assert_equal(rmse1_df.columns, ['rmse'])\n",
    "np.testing.assert_equal(rmse2_df.columns, ['rmse'])\n",
    "np.testing.assert_equal(rmse3_df.columns, ['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "acb1e1944cf0ec1381c9e168bcb007fe",
     "grade": false,
     "grade_id": "cell-2554e0a148260c25",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Assign the best cross validated model to a variable `best_model` below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa884e51878e5a17c9e2290add9457d9",
     "grade": false,
     "grade_id": "cell-c90e54ce6ce997f3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# assign best model (the best pipeline transformer) to a variable best_model below\n",
    "best_model = Pipeline(stages=[feature.VectorAssembler(inputCols = ['Region_A', 'Region_C', 'Region_D', 'Region_E','GRE_Score', 'TOEFL_Score', 'CGPA', 'University_Rating'], \n",
    "                                              outputCol='features'),\n",
    "                              regression.LinearRegression(featuresCol='features', labelCol='Chance_of_Admit')\n",
    "                              ]).fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "02183f5be1cfa4d961324c345ebde91b",
     "grade": true,
     "grade_id": "cell-35afdf9356e2d8c0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (1 pts)\n",
    "np.testing.assert_equal(type(best_model), pyspark.ml.pipeline.PipelineModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "65425c746f594ab1e9ce0f8505a7d704",
     "grade": false,
     "grade_id": "cell-a99d0caf3a210263",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Estimate generalization performance with RMSE\n",
    "\n",
    "Create a variable `rmse_best_df` that contains the RMSE of the best model on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|             rmse|\n",
      "+-----------------+\n",
      "|0.069007398603243|\n",
      "+-----------------+\n",
      "\n",
      "+-------------------+\n",
      "|               rmse|\n",
      "+-------------------+\n",
      "|0.06337052069366889|\n",
      "+-------------------+\n",
      "\n",
      "+--------------------+\n",
      "|                rmse|\n",
      "+--------------------+\n",
      "|0.049874633584238465|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rmse1_df = pipe_model1.transform(testing_df).select(rmse)\n",
    "rmse2_df = pipe_model2.transform(testing_df).select(rmse)\n",
    "rmse3_df = pipe_model3.transform(testing_df).select(rmse)\n",
    "\n",
    "rmse1_df.show()\n",
    "rmse2_df.show()\n",
    "rmse3_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d1abdc50e622c6c1356c761b7d616188",
     "grade": false,
     "grade_id": "cell-1ecb77ce154ee874",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "rmse_best_df = pipe_model3.transform(testing_df).select(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "97b09637da7cc6b5f5feccc6984c5b9a",
     "grade": true,
     "grade_id": "cell-4d8dbfbdf95c6bc6",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (2 pts)\n",
    "np.testing.assert_equal(rmse_best_df.count(), 1)\n",
    "np.testing.assert_equal(rmse_best_df.columns, ['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5356a7b0eec1cf5398a4aafcb9b5d09d",
     "grade": false,
     "grade_id": "cell-737b6d13dffc6cd9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(1 pts)** What is the best estimated generalization performance of the best model? Answer in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2cf756b46ea0129cd0e630946aa2fb1a",
     "grade": true,
     "grade_id": "cell-3f5687cd81273841",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|          accuracy|\n",
      "+------------------+\n",
      "|0.7434694764540205|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (1 pts)\n",
    "best_model.\\\n",
    "    transform(testing_df).\\\n",
    "    select(fn.avg(fn.expr('prediction')).alias('accuracy')).\\\n",
    "    show() \n",
    "# 74% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do inference with best model\n",
    "\n",
    "Assume that model 3 is the best one. Redefine a new pipeline for this model called `pipe_model_best` and fit it to the **entire training data** (all of `dummy_df`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c481548582d0228e36909c72d902ab6",
     "grade": false,
     "grade_id": "cell-e208c1a9d8454894",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create `pipe_model_best` below\n",
    "pipe_model_best = Pipeline(stages=[feature.VectorAssembler(inputCols = ['Region_A', 'Region_C', 'Region_D', 'Region_E','GRE_Score', 'TOEFL_Score', 'CGPA', 'University_Rating'], \n",
    "                                              outputCol='features'),\n",
    "                              regression.LinearRegression(featuresCol='features', labelCol='Chance_of_Admit')\n",
    "                              ]).fit(dummy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6a41b48cd0aa92ed02d559a50978e9b7",
     "grade": true,
     "grade_id": "cell-2daf591ae711f6d5",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (2 pts) check that the model was fitted correctly\n",
    "np.testing.assert_equal(type(pipe_model_best.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_model_best.stages[1]), regression.LinearRegressionModel)\n",
    "np.testing.assert_array_equal(pipe_model_best.stages[1].coefficients.shape, (8,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "16063f699d921a471e74c981316bafdf",
     "grade": false,
     "grade_id": "cell-d6e2ab884588f873",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(3 pts)** Assume that all features on `dummy_df` were comparable (i.e., standardized). Taking region B as the baseline, what are the top 2 most important features for *increasing chance of admit* and the top 2 most important features for *decreasing chance of admit*? Answer below with code and comments to support your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "526ee418f78e447d0041045b43ccdfb0",
     "grade": true,
     "grade_id": "cell-1ace5536c0322bdb",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2330398944623449"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "import math\n",
    "intercept = pipe_model_best.stages[-1].intercept\n",
    "\n",
    "math.exp(intercept)\n",
    "\n",
    "# when dependent variables = 0, region b predicted chance of admission is 0.233"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CGPA</td>\n",
       "      <td>0.136576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Region_D</td>\n",
       "      <td>0.020523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Region_C</td>\n",
       "      <td>0.012116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>University_Rating</td>\n",
       "      <td>0.011584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Region_A</td>\n",
       "      <td>0.005942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature  coefficients\n",
       "6               CGPA      0.136576\n",
       "2           Region_D      0.020523\n",
       "1           Region_C      0.012116\n",
       "7  University_Rating      0.011584\n",
       "0           Region_A      0.005942"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increase = pd.DataFrame({'feature':pipe_model_best.stages[0].getInputCols(), 'coefficients':pipe_model_best.stages[-1].coefficients.toArray() })\n",
    "increase.sort_values('coefficients', ascending=False).head(5)\n",
    "\n",
    "# exp(intercept) + ln(coefficients)\n",
    "\n",
    "# when CGPA increases, chance of admission is predicted to increase by 14%\n",
    "\n",
    "# when University Ranking increases, chance of admission is predicted to increase by 1%\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Region_E</td>\n",
       "      <td>0.000489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GRE_Score</td>\n",
       "      <td>0.002135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TOEFL_Score</td>\n",
       "      <td>0.002663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  coefficients\n",
       "3     Region_E      0.000489\n",
       "4    GRE_Score      0.002135\n",
       "5  TOEFL_Score      0.002663"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decrease = pd.DataFrame({'feature':pipe_model_best.stages[0].getInputCols(), 'coefficients':pipe_model_best.stages[-1].coefficients.toArray() })\n",
    "decrease.sort_values('coefficients', ascending=True).head(3)\n",
    "\n",
    "# 2 most important features for decreasing chance of admit GRE score and TOEFL \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
