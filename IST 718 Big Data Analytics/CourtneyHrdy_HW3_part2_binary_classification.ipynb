{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "76751541fd4e986454a49cc04ffd4491",
     "grade": false,
     "grade_id": "cell-fd57f7abd895c55d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Professor: Daniel Acuna <deacuna@syr.edu>\n",
    "\n",
    "## General instructions:\n",
    "\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers either from your classmates or from the internet__\n",
    "- You can put the homework files anywhere you want in your http://notebook.acuna.io workspace but _do not change_ the file names. The TAs and the professor use these names to grade your homework.\n",
    "- Remove or comment out code that contains `raise NotImplementedError`. This is mainly to make the `assert` statement fail if nothing is submitted.\n",
    "- The tests shown in some cells (i.e., `assert` and `np.testing.` statements) are used to grade your answers. **However, the professor and TAs will use __additional__ test for your answer. Think about cases where your code should run even if it passess all the tests you see.**\n",
    "- Before downloading and submitting your work through Blackboard, remember to save and press `Validate` (or go to \n",
    "`Kernel`$\\rightarrow$`Restart and Run All`). \n",
    "- Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the packages needed for this part\n",
    "# create spark and sparkcontext objects\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "import pyspark\n",
    "from pyspark.ml import feature, regression, Pipeline, classification, pipeline, evaluation\n",
    "from pyspark.sql import functions as fn, Row\n",
    "from pyspark import sql\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6f64982b8a3e22b6a1dfa5645995b2ae",
     "grade": false,
     "grade_id": "cell-84b632357d439c8b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "18b1f0bb96201e11ac44db3cfec8d79e",
     "grade": false,
     "grade_id": "cell-47f802f8b879145d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this section, you are going to develop a SMS spam detector based on logistic regression. This is the same idea behind sentiment analysis, but instead of predicting positive sentiment vs negative sentiment, you are going to predict whether a SMS text is spam or not.\n",
    "\n",
    "The dataset will be in `sms_spam_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "07ac3cd916a4d265a166256ad820dca5",
     "grade": false,
     "grade_id": "cell-2fc415e23f429e6b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sms_spam_df = spark.read.csv('sms_spam.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd1ceb68e6ecb69a2f9eb60faea19fad",
     "grade": false,
     "grade_id": "cell-e1b24d4d3df82dde",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Question 2.1\n",
    "\n",
    "Encode the `type` column to be 1 for `spam` and 0 for `ham` and store the result in `sms_spam2_df`. Besides, assign the count of spam to `spam_count` and the count of ham to `ham_count`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eca09f645c3e6ba100cad98eb17c67c2",
     "grade": false,
     "grade_id": "cell-7d71c3cf0aebba7f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create sms_spam2_df below\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer = StringIndexer(inputCol='type', outputCol='encoded_type')\n",
    "sms_spam2_df = indexer.fit(sms_spam_df).transform(sms_spam_df)\n",
    "ham_count = sms_spam2_df.where(fn.col('encoded_type') == 0).count()\n",
    "spam_count = sms_spam2_df.where(fn.col('encoded_type') == 1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+------------+\n",
      "|type|                text|encoded_type|\n",
      "+----+--------------------+------------+\n",
      "| ham|Go until jurong p...|         0.0|\n",
      "| ham|Ok lar... Joking ...|         0.0|\n",
      "|spam|Free entry in 2 a...|         1.0|\n",
      "| ham|U dun say so earl...|         0.0|\n",
      "| ham|Nah I don't think...|         0.0|\n",
      "|spam|FreeMsg Hey there...|         1.0|\n",
      "| ham|Even my brother i...|         0.0|\n",
      "| ham|As per your reque...|         0.0|\n",
      "|spam|WINNER!! As a val...|         1.0|\n",
      "|spam|Had your mobile 1...|         1.0|\n",
      "| ham|I'm gonna be home...|         0.0|\n",
      "|spam|SIX chances to wi...|         1.0|\n",
      "|spam|URGENT! You have ...|         1.0|\n",
      "| ham|I've been searchi...|         0.0|\n",
      "| ham|I HAVE A DATE ON ...|         0.0|\n",
      "|spam|XXXMobileMovieClu...|         1.0|\n",
      "| ham|Oh k...i'm watchi...|         0.0|\n",
      "| ham|Eh u remember how...|         0.0|\n",
      "| ham|Fine if that's th...|         0.0|\n",
      "|spam|England v Macedon...|         1.0|\n",
      "+----+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check here\n",
    "sms_spam2_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a8c5e06fedfc3948ad0fbb5bca9e635f",
     "grade": true,
     "grade_id": "cell-fd53856d153a78b0",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_array_equal(\n",
    "    sms_spam2_df.groupBy('type').count().orderBy('type').rdd.map(lambda x: x['count']).collect(),\n",
    "    [4827, 747])\n",
    "np.testing.assert_array_equal(spam_count, 747)\n",
    "np.testing.assert_array_equal(ham_count, 4827)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1197a7c2907babcd6224b19400f84fd4",
     "grade": false,
     "grade_id": "cell-2b8e3e4ab912ade5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Question 2.2: tfidf feature engineering\n",
    "Create a pipeline that combines a `Tokenizer`, `CounterVectorizer`, and a `IDF` estimator to compute the tfidf vectors of each SMS. Fit this pipeline and assign the pipeline transformer to a variable `tfidf_pipeline`. The `Tokenizer` step should create a column `words`, the `CounterVectorizer` step should create a column `tf`, and the `IDF` step should create a column `tfidf`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{tf-idf}_{ij} = f_{ij} \\log \\frac{|D|+1}{f_i+1}\n",
    "$$\n",
    "\n",
    "$f_i$ is number of documents that contain word $i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer\n",
    "Tokenizer = Tokenizer().setInputCol('text').setOutputCol('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b7e5f06cbd4cb61622663886e7511c0",
     "grade": false,
     "grade_id": "cell-b5ee789cf3aec7fa",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "CounterVectorizer = CountVectorizer(minTF=1., minDF=5., vocabSize=2**17).setInputCol('words').setOutputCol('tf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import IDF\n",
    "idf = IDF().\\\n",
    "    setInputCol('tf').\\\n",
    "    setOutputCol('tfidf')\n",
    "\n",
    "tfidf_pipeline = Pipeline(stages=[Tokenizer, CounterVectorizer, idf]).fit(sms_spam2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+------------+--------------------+--------------------+--------------------+\n",
      "|type|                text|encoded_type|               words|                  tf|               tfidf|\n",
      "+----+--------------------+------------+--------------------+--------------------+--------------------+\n",
      "| ham|Go until jurong p...|         0.0|[go, until, juron...|(2005,[8,42,51,65...|(2005,[8,42,51,65...|\n",
      "| ham|Ok lar... Joking ...|         0.0|[ok, lar..., joki...|(2005,[5,74,404,5...|(2005,[5,74,404,5...|\n",
      "|spam|Free entry in 2 a...|         1.0|[free, entry, in,...|(2005,[0,3,8,20,5...|(2005,[0,3,8,20,5...|\n",
      "| ham|U dun say so earl...|         0.0|[u, dun, say, so,...|(2005,[5,22,60,14...|(2005,[5,22,60,14...|\n",
      "| ham|Nah I don't think...|         0.0|[nah, i, don't, t...|(2005,[0,1,66,86,...|(2005,[0,1,66,86,...|\n",
      "|spam|FreeMsg Hey there...|         1.0|[freemsg, hey, th...|(2005,[0,2,6,10,1...|(2005,[0,2,6,10,1...|\n",
      "| ham|Even my brother i...|         0.0|[even, my, brothe...|(2005,[0,7,9,13,2...|(2005,[0,7,9,13,2...|\n",
      "| ham|As per your reque...|         0.0|[as, per, your, r...|(2005,[0,10,11,44...|(2005,[0,10,11,44...|\n",
      "|spam|WINNER!! As a val...|         1.0|[winner!!, as, a,...|(2005,[0,2,3,14,1...|(2005,[0,2,3,14,1...|\n",
      "|spam|Had your mobile 1...|         1.0|[had, your, mobil...|(2005,[0,4,5,10,1...|(2005,[0,4,5,10,1...|\n",
      "| ham|I'm gonna be home...|         0.0|[i'm, gonna, be, ...|(2005,[0,1,6,28,3...|(2005,[0,1,6,28,3...|\n",
      "|spam|SIX chances to wi...|         1.0|[six, chances, to...|(2005,[0,6,40,48,...|(2005,[0,6,40,48,...|\n",
      "|spam|URGENT! You have ...|         1.0|[urgent!, you, ha...|(2005,[0,2,3,4,8,...|(2005,[0,2,3,4,8,...|\n",
      "| ham|I've been searchi...|         0.0|[i've, been, sear...|(2005,[0,1,2,3,4,...|(2005,[0,1,2,3,4,...|\n",
      "| ham|I HAVE A DATE ON ...|         0.0|[i, have, a, date...|(2005,[1,3,14,16,...|(2005,[1,3,14,16,...|\n",
      "|spam|XXXMobileMovieClu...|         1.0|[xxxmobilemoviecl...|(2005,[0,4,8,11,2...|(2005,[0,4,8,11,2...|\n",
      "| ham|Oh k...i'm watchi...|         0.0|[oh, k...i'm, wat...|(2005,[159,314],[...|(2005,[159,314],[...|\n",
      "| ham|Eh u remember how...|         0.0|[eh, u, remember,...|(2005,[1,5,20,46,...|(2005,[1,5,20,46,...|\n",
      "| ham|Fine if that's th...|         0.0|[fine, if, that's...|(2005,[4,5,30,59,...|(2005,[4,5,30,59,...|\n",
      "|spam|England v Macedon...|         1.0|[england, v, mace...|(2005,[0,4,29,81,...|(2005,[0,4,29,81,...|\n",
      "+----+--------------------+------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check pipeline result\n",
    "tfidf_pipeline.transform(sms_spam2_df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2587fd7e7a74b3de9f4a9a01e8b6b0a",
     "grade": true,
     "grade_id": "cell-957dca13bb7c47e7",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_array_equal([type(s) for s in tfidf_pipeline.stages],\n",
    "                              [feature.Tokenizer, feature.CountVectorizerModel, feature.IDFModel])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ac92bbb430037e8579ef7d889395003a",
     "grade": false,
     "grade_id": "cell-dce1d79fb97e994a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Question 2.3: uppercase feature\n",
    "\n",
    "Typical spam messages contain words that are upper case. Create a dataframe `sms_spam3_df` where you add a new column `has_uppercase` which contains an integer `1` if the first sequence of uppercase letters is longer or equal to 3 and an integer `0` otherwise. You can extract sequence of 3 or more uppercase letters by using the regular expression `[A-Z]{3,}`. You will use the function `fn.regexp_extract` to find those sequences and extract the first one (e.g., with index 0) and then use `fn.length` to compute the length of such sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20a4b0c6fb965517f0a65a8c19606f13",
     "grade": false,
     "grade_id": "cell-8379dd6c53f8fdb4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create sms_spam3_df below\n",
    "\n",
    "sms = sms_spam2_df.select('type', 'text', fn.regexp_extract('text', '[A-Z]{3,}', 0).alias('uppercase'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+-------------+\n",
      "|type|                text|has_uppercase|\n",
      "+----+--------------------+-------------+\n",
      "| ham|Go until jurong p...|            0|\n",
      "| ham|Ok lar... Joking ...|            0|\n",
      "|spam|Free entry in 2 a...|            0|\n",
      "| ham|U dun say so earl...|            0|\n",
      "| ham|Nah I don't think...|            0|\n",
      "|spam|FreeMsg Hey there...|            0|\n",
      "| ham|Even my brother i...|            0|\n",
      "| ham|As per your reque...|            0|\n",
      "|spam|WINNER!! As a val...|            1|\n",
      "|spam|Had your mobile 1...|            1|\n",
      "| ham|I'm gonna be home...|            0|\n",
      "|spam|SIX chances to wi...|            1|\n",
      "|spam|URGENT! You have ...|            1|\n",
      "| ham|I've been searchi...|            0|\n",
      "| ham|I HAVE A DATE ON ...|            1|\n",
      "|spam|XXXMobileMovieClu...|            1|\n",
      "| ham|Oh k...i'm watchi...|            0|\n",
      "| ham|Eh u remember how...|            0|\n",
      "| ham|Fine if that's th...|            0|\n",
      "|spam|England v Macedon...|            1|\n",
      "+----+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexer = StringIndexer(inputCol='uppercase', outputCol='hasuppercase')\n",
    "sms_spam3 = indexer.fit(sms).transform(sms)\n",
    "sms_spam3\n",
    "df = sms_spam3.withColumn('has_uppercase', fn.when(fn.col('hasuppercase') > 0, 1.0).otherwise(0.))\n",
    "\n",
    "sms_spam3_df = df.select('type', 'text', fn.col('has_uppercase').cast(\"int\"))\n",
    "\n",
    "sms_spam3_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "183aa0776cb5b99dd9e83e0528d03217",
     "grade": false,
     "grade_id": "cell-b62acdccd294ea11",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The first three messages with `has_uppercase == 1` are as follows:\n",
    "\n",
    "```python\n",
    "sms_spam3_df.where('has_uppercase == 1').take(3)\n",
    "```\n",
    "\n",
    "```console\n",
    "[Row(type=1, text='WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.', has_uppercase=1),\n",
    " Row(type=1, text='Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030', has_uppercase=1),\n",
    " Row(type=1, text='SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info', has_uppercase=1)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d762f9d5a3e2fae0e7e1ce9a090938e8",
     "grade": false,
     "grade_id": "cell-8ef4beb7de83fd4b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(type='spam', text='WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.', has_uppercase=1),\n",
       " Row(type='spam', text='Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030', has_uppercase=1),\n",
       " Row(type='spam', text='SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info', has_uppercase=1)]"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try it here\n",
    "sms_spam3_df.where('has_uppercase == 1').take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1925a0bc030ba4c8ad9c5b39426caefd",
     "grade": true,
     "grade_id": "cell-48ea7a4e9f38040c",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_equal(set(sms_spam3_df.columns), {'has_uppercase', 'text', 'type'})\n",
    "np.testing.assert_equal(type(sms_spam3_df.schema['has_uppercase'].dataType), sql.types.IntegerType)\n",
    "np.testing.assert_equal(sms_spam3_df.rdd.map(lambda x : x['has_uppercase']).sum(), 891)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f14d4b1f6f7af346a2b83b19d162e5c1",
     "grade": false,
     "grade_id": "cell-234e1ff6aefffd33",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Question 2.4: Compare models\n",
    "\n",
    "Using the following splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e77619ff80707ea32db4ec2717d9fcfa",
     "grade": false,
     "grade_id": "cell-2631206b3ba12497",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "training_df, validation_df, testing_df = sms_spam2_df.randomSplit([0.6, 0.3, 0.1], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "193ba2e4521cd91d991c02a489c273c1",
     "grade": false,
     "grade_id": "cell-e0de63de02506054",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3311, 1709, 554]"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[training_df.count(), validation_df.count(), testing_df.count()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "859fec29e12926ce3c7851508f6d7473",
     "grade": false,
     "grade_id": "cell-81a7e8bdddc53846",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(15 pts)** Create pipelines where the first stage is the `tfidf_pipeline` created above and the second stage is a `LogisticRegression` model with different regularization parameters ($\\lambda$) and elastic net mixture ($\\alpha$) as following:\n",
    "$$\\lambda = [0, 0.02, 0.1] $$\n",
    "$$\\alpha = [0.2, 0.4] $$\n",
    "\n",
    "Try different combinations of $\\lambda$ and $\\alpha$ (6 combinations) to find out best parameters by using the area under the curve as the estimator. Fit those pipelines to the appropriate data split and assign the pipeline with the best model to a variable `best_model`. Also, assign $\\lambda$ and $\\alpha$ of the best model to `best_model_lambda` and `best_model_alpha`.\n",
    "\n",
    "For example, the AUC on training of the first model is perfect:\n",
    "\n",
    "```\n",
    "evaluator.evaluate(lr_pipeline1.transform(training_df))\n",
    "```\n",
    "\n",
    "```console\n",
    "1.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9080584551148206"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, \\\n",
    "    MulticlassClassificationEvaluator, \\\n",
    "    RegressionEvaluator\n",
    "\n",
    "pipeline_cv_estimator = Pipeline(stages=[Tokenizer, CounterVectorizer]).fit(sms_spam2_df)\n",
    "tfidf_pipeline = Pipeline(stages=[pipeline_cv_estimator, idf]).fit(sms_spam2_df)\n",
    "\n",
    "lr = LogisticRegression().\\\n",
    "    setLabelCol('encoded_type').\\\n",
    "    setFeaturesCol('tfidf').\\\n",
    "    setRegParam(0.0).\\\n",
    "    setMaxIter(100).\\\n",
    "    setElasticNetParam(0.) # logistic regression\n",
    "\n",
    "\n",
    "lr_pipeline = Pipeline(stages=[tfidf_pipeline, lr]).fit(training_df) # pipeline \n",
    "evaluator = BinaryClassificationEvaluator(labelCol='encoded_type')\n",
    "evaluator.evaluate(lr_pipeline.transform(testing_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "vocabulary = tfidf_pipeline.stages[0].stages[-1].vocabulary\n",
    "weights = lr_pipeline.stages[-1].coefficients.toArray()\n",
    "coeffs_df = pd.DataFrame({'word': vocabulary, 'weight': weights})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>his</td>\n",
       "      <td>-26.905969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>ok...</td>\n",
       "      <td>-25.307068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>later.</td>\n",
       "      <td>-24.973442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>snow</td>\n",
       "      <td>-18.903645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>see</td>\n",
       "      <td>-18.578804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>called</td>\n",
       "      <td>-16.627778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>where</td>\n",
       "      <td>-16.045486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>then...</td>\n",
       "      <td>-15.563710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>liked</td>\n",
       "      <td>-15.550081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>nobody</td>\n",
       "      <td>-14.661711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word     weight\n",
       "205       his -26.905969\n",
       "357     ok... -25.307068\n",
       "452    later. -24.973442\n",
       "1201     snow -18.903645\n",
       "83        see -18.578804\n",
       "335    called -16.627778\n",
       "120     where -16.045486\n",
       "1483  then... -15.563710\n",
       "1302    liked -15.550081\n",
       "1179   nobody -14.661711"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs_df.sort_values('weight').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9745441892832293"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_par = 0.02\n",
    "alpha_par = 1.0\n",
    "lr2 = LogisticRegression().\\\n",
    "    setLabelCol('encoded_type').\\\n",
    "    setFeaturesCol('tfidf').\\\n",
    "    setRegParam(lambda_par).\\\n",
    "    setMaxIter(100).\\\n",
    "    setElasticNetParam(alpha_par)\n",
    "\n",
    "lr_model2 = Pipeline(stages=[Tokenizer, CounterVectorizer, idf, lr2]).fit(training_df)\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='encoded_type')\n",
    "evaluator.evaluate(lr_model2.transform(testing_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_par = 1.0\n",
    "alpha_par = 1.0\n",
    "lr3 = LogisticRegression().\\\n",
    "    setLabelCol('encoded_type').\\\n",
    "    setFeaturesCol('tfidf').\\\n",
    "    setRegParam(lambda_par).\\\n",
    "    setMaxIter(100).\\\n",
    "    setElasticNetParam(alpha_par)\n",
    "\n",
    "lr_model3 = Pipeline(stages=[Tokenizer, CounterVectorizer, idf, lr3]).fit(training_df)\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='encoded_type')\n",
    "evaluator.evaluate(lr_model3.transform(testing_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9804453723034107"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_par = 1.0\n",
    "alpha_par = 0.02\n",
    "lr4 = LogisticRegression().\\\n",
    "    setLabelCol('encoded_type').\\\n",
    "    setFeaturesCol('tfidf').\\\n",
    "    setRegParam(lambda_par).\\\n",
    "    setMaxIter(100).\\\n",
    "    setElasticNetParam(alpha_par)\n",
    "\n",
    "lr_model4 = Pipeline(stages=[Tokenizer, CounterVectorizer, idf, lr4]).fit(training_df)\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='encoded_type')\n",
    "evaluator.evaluate(lr_model4.transform(testing_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9908420320111356"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_par = 1.0\n",
    "lr5 = LogisticRegression().\\\n",
    "    setLabelCol('encoded_type').\\\n",
    "    setFeaturesCol('tfidf').\\\n",
    "    setRegParam(alpha_par).\\\n",
    "    setMaxIter(100).\\\n",
    "    setElasticNetParam(0.0)\n",
    "\n",
    "lr_model5 = Pipeline(stages=[Tokenizer, CounterVectorizer, idf, lr5]).fit(training_df)\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='encoded_type')\n",
    "evaluator.evaluate(lr_model5.transform(testing_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9908420320111356"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_par = 1.0\n",
    "lr6= LogisticRegression().\\\n",
    "    setLabelCol('encoded_type').\\\n",
    "    setFeaturesCol('tfidf').\\\n",
    "    setRegParam(lambda_par).\\\n",
    "    setMaxIter(100).\\\n",
    "    setElasticNetParam(0.0)\n",
    "\n",
    "lr_model6 = Pipeline(stages=[Tokenizer, CounterVectorizer, idf, lr6]).fit(training_df)\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='encoded_type')\n",
    "evaluator.evaluate(lr_model6.transform(testing_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "30f0ce55dd31e64fd39649be4b8a85d9",
     "grade": false,
     "grade_id": "cell-0402f373b78b9f40",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9835908141962438"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_lambda = 0.02\n",
    "best_model_alpha = 0.2\n",
    "\n",
    "lr7 = LogisticRegression().\\\n",
    "    setLabelCol('encoded_type').\\\n",
    "    setFeaturesCol('tfidf').\\\n",
    "    setRegParam(best_model_lambda).\\\n",
    "    setMaxIter(100).\\\n",
    "    setElasticNetParam(best_model_alpha)\n",
    "\n",
    "best_model1 = Pipeline(stages=[Tokenizer, CounterVectorizer, idf, lr7]).fit(training_df) # estimator\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='encoded_type')\n",
    "AUC_best = evaluator.evaluate(best_model1.transform(testing_df)) #transformer\n",
    "AUC_best # lower AUC, higher precision (1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9846068197633973"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_lambda = 0.02\n",
    "best_model_alpha = 0.2\n",
    "\n",
    "pipeline_cv_estimator = Pipeline(stages=[Tokenizer, CounterVectorizer]).fit(sms_spam2_df)\n",
    "tfidf_pipeline = Pipeline(stages=[pipeline_cv_estimator, idf]).fit(sms_spam2_df)\n",
    "\n",
    "lr8 = LogisticRegression().\\\n",
    "    setLabelCol('encoded_type').\\\n",
    "    setFeaturesCol('tfidf').\\\n",
    "    setRegParam(best_model_lambda).\\\n",
    "    setMaxIter(100).\\\n",
    "    setElasticNetParam(best_model_alpha) # logistic regression\n",
    "\n",
    "\n",
    "\n",
    "best_model = Pipeline(stages=[tfidf_pipeline, lr8]).fit(training_df) # uses tdif pipeline \n",
    "evaluator = BinaryClassificationEvaluator(labelCol='encoded_type')\n",
    "AUC_best = evaluator.evaluate(best_model.transform(testing_df)) #transformer\n",
    "AUC_best # precision 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "558f62343a08e5d105e4c726cac81d89",
     "grade": true,
     "grade_id": "cell-26ba2c28a8128b83",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (15 pts)\n",
    "np.testing.assert_equal(type(best_model), pipeline.PipelineModel)\n",
    "\n",
    "np.testing.assert_array_equal([type(s) for s in best_model.stages],\n",
    "                              [pipeline.PipelineModel, classification.LogisticRegressionModel])\n",
    "\n",
    "np.testing.assert_equal(best_model_lambda, 0.02)\n",
    "np.testing.assert_equal(best_model_alpha, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2.5: Generalization of best model\n",
    "\n",
    "Using the right split and the best model selected before, compute the generalization performance and assign it to a variable `AUC_best`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea7e1b7bd7728a0740d64150079a79be",
     "grade": false,
     "grade_id": "cell-a39d41daf0a9fbdf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9846068197633973"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_lambda = 0.02\n",
    "best_model_alpha = 0.2\n",
    "\n",
    "pipeline_cv_estimator = Pipeline(stages=[Tokenizer, CounterVectorizer]).fit(sms_spam2_df)\n",
    "tfidf_pipeline = Pipeline(stages=[pipeline_cv_estimator, idf]).fit(sms_spam2_df)\n",
    "\n",
    "lr8 = LogisticRegression().\\\n",
    "    setLabelCol('encoded_type').\\\n",
    "    setFeaturesCol('tfidf').\\\n",
    "    setRegParam(best_model_lambda).\\\n",
    "    setMaxIter(100).\\\n",
    "    setElasticNetParam(best_model_alpha) # logistic regression\n",
    "\n",
    "\n",
    "\n",
    "best_model = Pipeline(stages=[tfidf_pipeline, lr8]).fit(training_df) # pipeline \n",
    "evaluator = BinaryClassificationEvaluator(labelCol='encoded_type')\n",
    "AUC_best = evaluator.evaluate(best_model.transform(testing_df)) #transformer\n",
    "AUC_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "451223249c780310c86e4f849cf21c47",
     "grade": true,
     "grade_id": "cell-c9c7380d0127aaa3",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_approx_equal(AUC_best, 0.9883924843423813, significant=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c2accb962a5b3a0a1f256562ac3e6796",
     "grade": false,
     "grade_id": "cell-401a2eb3f9951e7c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Using the same split and the best model, compute and assign `precision`, `recall` and `f1_score`. You should first count the numbers in the confusion matrix, and then compute these metrics based on the formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Prevalence**: (TP+FN) / everything\n",
    "- **Precision**: TP / (TP + FP)\n",
    "- **Sensitivity**, **Recall**, or **True positive rate**: TP / true condition positive\n",
    "- **Specificity**: TN / true condition negative\n",
    "- **F1**: $\\frac{2*precision*recall}{precision + recall}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[479.   0.]\n",
      " [ 15.  60.]]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "dft = best_model1.transform(testing_df)\n",
    "\n",
    "df = dft.select(['prediction', 'encoded_type'])\n",
    "metrics = MulticlassMetrics(df.rdd.map(tuple))\n",
    "\n",
    "print(metrics.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = metrics.precision(1.0)\n",
    "recall = metrics.recall(1.0)\n",
    "f1_score = metrics.fMeasure(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d215f5a792d259d1696a46dbc7496433",
     "grade": false,
     "grade_id": "cell-0584bc905b7b24cf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98       479\n",
      "         1.0       1.00      0.80      0.89        75\n",
      "\n",
      "    accuracy                           0.97       554\n",
      "   macro avg       0.98      0.90      0.94       554\n",
      "weighted avg       0.97      0.97      0.97       554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model = best_model1.transform(testing_df)\n",
    "\n",
    "y_true = dft.select(['encoded_type']).collect()\n",
    "y_pred = dft.select(['prediction']).collect()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "437bd313abaf2e1be0a19a4ac282e196",
     "grade": true,
     "grade_id": "cell-6feadc1a5e40bc0f",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_array_almost_equal([precision, recall, f1_score],\n",
    "    [1.0, 0.7976190476190477, 0.8874172185430463], decimal=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9c9025137952e3c736d816f06ce16126",
     "grade": false,
     "grade_id": "cell-1998be9336b4fd27",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Question 2.6: Inference\n",
    "\n",
    "Use the best pipeline fitted above (`best_model`) to create Pandas dataframes that contain the most negative words and the most positive words. In particular, create a dataframe `positive_words` with the columns `word` and `weight` with the top 20 positive words, sorted by descending coefficient. Similarly create a `negative_words` Pandas dataframe with the top 20 negative words where the coefficient are sorted in ascending order. **Hint: follow the `sentiment_analysis.ipynb` notebook in the repo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = best_model1.stages[1].vocabulary\n",
    "weights = best_model1.stages[-1].coefficients.toArray()\n",
    "coeffs_df = pd.DataFrame({'word': vocabulary, 'weight': weights})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "543b279011d3bcaf54625aa57a526352",
     "grade": false,
     "grade_id": "cell-a4ab8b83f44edd98",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.885048977821447"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_words = coeffs_df.sort_values('weight', ascending=False).head(20)\n",
    "positive_words.weight.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.4337804407269388"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_words = coeffs_df.sort_values('weight', ascending=True).head(20)\n",
    "negative_words.weight.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>won</td>\n",
       "      <td>0.624268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>call</td>\n",
       "      <td>0.529299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>onto</td>\n",
       "      <td>0.479627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>ringtone</td>\n",
       "      <td>0.466865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>txt</td>\n",
       "      <td>0.454826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>sex</td>\n",
       "      <td>0.412815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>service</td>\n",
       "      <td>0.383503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>order</td>\n",
       "      <td>0.382584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>now!</td>\n",
       "      <td>0.382461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>games</td>\n",
       "      <td>0.374132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>awarded</td>\n",
       "      <td>0.369311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>unsubscribe</td>\n",
       "      <td>0.367823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>ltd,</td>\n",
       "      <td>0.348232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>stop</td>\n",
       "      <td>0.345313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>numbers</td>\n",
       "      <td>0.341162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>reply</td>\n",
       "      <td>0.331055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>18+</td>\n",
       "      <td>0.327352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>mobile</td>\n",
       "      <td>0.326707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>£250</td>\n",
       "      <td>0.320472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>claim</td>\n",
       "      <td>0.317241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word    weight\n",
       "162           won  0.624268\n",
       "15           call  0.529299\n",
       "1263         onto  0.479627\n",
       "372      ringtone  0.466865\n",
       "87            txt  0.454826\n",
       "671           sex  0.412815\n",
       "215       service  0.383503\n",
       "736         order  0.382584\n",
       "159          now!  0.382461\n",
       "923         games  0.374132\n",
       "327       awarded  0.369311\n",
       "1169  unsubscribe  0.367823\n",
       "1194         ltd,  0.348232\n",
       "103          stop  0.345313\n",
       "969       numbers  0.341162\n",
       "98          reply  0.331055\n",
       "623           18+  0.327352\n",
       "88         mobile  0.326707\n",
       "648          £250  0.320472\n",
       "120         claim  0.317241"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine positive vocabulary\n",
    "positive_words.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i</td>\n",
       "      <td>-0.271900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>me</td>\n",
       "      <td>-0.133675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>friends</td>\n",
       "      <td>-0.120932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>lose</td>\n",
       "      <td>-0.099188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>if</td>\n",
       "      <td>-0.095204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>my</td>\n",
       "      <td>-0.087518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>i'll</td>\n",
       "      <td>-0.080973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>but</td>\n",
       "      <td>-0.072798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>i'm</td>\n",
       "      <td>-0.071817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>i've</td>\n",
       "      <td>-0.050437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>its</td>\n",
       "      <td>-0.045952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>u</td>\n",
       "      <td>-0.045093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>in</td>\n",
       "      <td>-0.041955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>come</td>\n",
       "      <td>-0.040229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>thats</td>\n",
       "      <td>-0.038226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td></td>\n",
       "      <td>-0.037958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>sir,</td>\n",
       "      <td>-0.032513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>so</td>\n",
       "      <td>-0.031292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>&amp;amp;</td>\n",
       "      <td>-0.023539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>did</td>\n",
       "      <td>-0.012583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word    weight\n",
       "1          i -0.271900\n",
       "11        me -0.133675\n",
       "359  friends -0.120932\n",
       "602     lose -0.099188\n",
       "29        if -0.095204\n",
       "9         my -0.087518\n",
       "75      i'll -0.080973\n",
       "26       but -0.072798\n",
       "27       i'm -0.071817\n",
       "161     i've -0.050437\n",
       "59       its -0.045952\n",
       "5          u -0.045093\n",
       "7         in -0.041955\n",
       "56      come -0.040229\n",
       "278    thats -0.038226\n",
       "20           -0.037958\n",
       "628     sir, -0.032513\n",
       "19        so -0.031292\n",
       "131    &amp; -0.023539\n",
       "111      did -0.012583"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine solutions\n",
    "negative_words.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e52fc9e300ae0de22cac8c1d2bb9b3bb",
     "grade": false,
     "grade_id": "cell-768b16040bab3cdb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The `positive_words` and `negative_words` dataframe should look like this:\n",
    "\n",
    "```python\n",
    "positive_words.head()\n",
    "```\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>word</th>\n",
    "      <th>weight</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>7263</th>\n",
    "      <td>sexy?</td>\n",
    "      <td>0.642738</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3555</th>\n",
    "      <td>widelive.com/index.</td>\n",
    "      <td>0.588182</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>15</th>\n",
    "      <td>call</td>\n",
    "      <td>0.537161</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>12237\t\t</th>\n",
    "      <td>08714712388</td>\n",
    "      <td>0.504090</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>81</th>\n",
    "      <td>txt</td>\n",
    "      <td>0.495005</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "and \n",
    "\n",
    "```python\n",
    "negative_words.head()\n",
    "```\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>word</th>\n",
    "      <th>weight</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>i</td>\n",
    "      <td>-0.183463</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3332</th>\n",
    "      <td>lose.</td>\n",
    "      <td>-0.074937</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3371</th>\n",
    "      <td>fightng</td>\n",
    "      <td>-0.074937</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3221</th>\n",
    "      <td>dificult</td>\n",
    "      <td>-0.074937</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>13</th>\n",
    "      <td>me</td>\n",
    "      <td>-0.065904</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f178fb76b9c4fa0a0381626e33bd5572",
     "grade": true,
     "grade_id": "cell-8893a62881db3a6e",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_equal(set(positive_words.columns), {'weight', 'word'})\n",
    "np.testing.assert_equal(set(negative_words.columns), {'weight', 'word'})\n",
    "np.testing.assert_approx_equal(positive_words.weight.sum(), 8.675741267346245, significant=1)\n",
    "np.testing.assert_approx_equal(negative_words.weight.sum(), -0.7292131526997235, significant=1)\n",
    "np.testing.assert_array_less(positive_words.weight.iloc[-1], positive_words.weight.iloc[0])\n",
    "np.testing.assert_array_less(negative_words.weight.iloc[0], negative_words.weight.iloc[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a117cd78874726c39a69e7b5e79ba76d",
     "grade": false,
     "grade_id": "cell-342e622b6b0900cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Question 2.7\n",
    "Use the dataframe `sms_spam3_df` to create a model where the first feature is `has_uppercase` and the next set of features are the tfidf of the text. Perform feature engineering in all features using a max absolute scaler ([`MaxAbsScaler`](https://spark.apache.org/docs/2.0.2/ml-features.html#maxabsscaler)). Do a logistic regression on the resulting scaled features with regularization parameter $\\lambda = 0.2$ and elastic net mixture $\\alpha=0.1$ for the entire data (all of `sms_spam3_df`). Since you have scaled all features to be within the same range, you can compare them. \n",
    "\n",
    "**(5 pts)** with code and comments, answer below\n",
    "\n",
    "1. is `has_uppercase` a feature that is positively or negative related to an SMS being spam?\n",
    "2. what is the ratio of the coefficient of `has_uppercase` to the biggest positive tfidf coefficient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark_pipes import pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol='type', outputCol='encoded_type')\n",
    "sms_spam3_df = indexer.fit(sms_spam3_df).transform(sms_spam3_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. pipeline for tfidf of the text\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "Tokenizer = Tokenizer().setInputCol('text').setOutputCol('words')\n",
    "\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "CounterVectorizer = CountVectorizer(minTF=1., minDF=5., vocabSize=2**17).setInputCol('words').setOutputCol('tf')\n",
    "\n",
    "from pyspark.ml.feature import IDF\n",
    "idf = IDF().\\\n",
    "    setInputCol('tf').\\\n",
    "    setOutputCol('tfidf')\n",
    "\n",
    "tfidf_pipeline = Pipeline(stages=[Tokenizer, CounterVectorizer, idf]).fit(sms_spam3_df)\n",
    "\n",
    "#tfidf = tfidf_pipeline.fit(sms_spam3_df)\n",
    "tfidf = tfidf_pipeline.transform(sms_spam3_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4eb4f1efc36f0c6ad437acdc9a744a51",
     "grade": true,
     "grade_id": "cell-ea94732643cb73ff",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, test = tfidf.randomSplit([0.8, 0.2], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = pipe(feature.VectorAssembler(inputCols=['has_uppercase', 'tfidf'], outputCol=\"features\"),\n",
    "              feature.MaxAbsScaler(inputCol='features', outputCol='Scaledfeatures'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_lambda = 0.2\n",
    "best_model_alpha = 0.1\n",
    "\n",
    "\n",
    "lr2 = LogisticRegression().\\\n",
    "    setLabelCol('encoded_type').\\\n",
    "    setFeaturesCol('Scaledfeatures').\\\n",
    "    setRegParam(best_model_lambda).\\\n",
    "    setMaxIter(100).\\\n",
    "    setElasticNetParam(best_model_alpha)\n",
    "\n",
    "bestmodel = Pipeline(stages=[model2, lr2]).fit(training) \n",
    "evaluator = BinaryClassificationEvaluator(labelCol='encoded_type')\n",
    "AUC = evaluator.evaluate(model.transform(test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 0.9451844869703176\n",
      "2. 0.4742783128057046\n"
     ]
    }
   ],
   "source": [
    "uppercoef = bestmodel.stages[-1].coefficients.toArray()[0]\n",
    "tfidfcoef = bestmodel.stages[-1].coefficients.toArray().max()\n",
    "print('1.', uppercoef) #1.  has_uppercase coef is positively correlated\n",
    "print('2.', uppercoef / tfidfcoef) #2. ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
